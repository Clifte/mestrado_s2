
\documentclass[ 
	% -- opções da classe memoir --
	article,			% indica que é um artigo acadêmico
	11pt,				% tamanho da fonte
	oneside,			% para impressão apenas no verso. Oposto a twoside
	a4paper,			% tamanho do papel. 
	% -- opções da classe abntex2 --
	%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
	%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
	%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
	%subsubsection=TITLE % títulos de subsubseções convertidos em letras maiúsculas
	% -- opções do pacote babel --
	english,			% idioma adicional para hifenização
	brazil,				% o último idioma é o principal do documento
	]{abntex2}


% --- 
% PACOTES
% ---

% ---
% Pacotes fundamentais 
% ---
\usepackage{cmap}				% Mapear caracteres especiais no PDF
\usepackage{lmodern}			% Usa a fonte Latin Modern
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{nomencl} 			% Lista de simbolos
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{csvsimple}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{pgffor}
%\usepackage[nolists,tablesfirst]{endfloat}
% ---
		
\usepackage{amsmath}		
		
		
% ---
% Pacotes adicionais, usados apenas no âmbito do Modelo Canônico do abnteX2
% ---
\usepackage{lipsum}				% para geração de dummy text
% ---
		
% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT
% ---



\def\pathForTaxaErroRejeicaBase#1#2{matlab/#1/#2/RejOpt/TaxaErroRejeicao.eps}

\def\pathForRejDec#1#2#3{{matlab/#1/#2/RejOpt/decReg/decRegion_#3_A}.eps}

\def\pathForEmpError#1#2{matlab/#1/#2/RejOpt/ErroEmpirico.eps}

\def\pathForAR#1#2{matlab/#1/#2/RejOpt/RejeicaoAcuracia.eps}


\def \importWRTable#1#2{
	\begin{tabular}[t]{c|c|c|c}%
	    \bfseries $W_r$ & 
	    \bfseries $\beta_o$ &
	    \bfseries $A(\beta_o)$ & 
	    \bfseries $R(\beta_o)$% specify table head 
	    \csvreader[no head]{matlab/#1/#2/RejOpt/WrsAccRej.csv}{}% use head of
	    % csv as column names
	    {\\\hline\csvcoli&\csvcolii&\csvcoliii&\csvcoliv}% specify your coloumns
	    % here
	    \\\hline
    \end{tabular}
}

 

%



% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		Nenhuma citação no texto.%
	\or
		Citado na página #2.%
	\else
		Citado #1 vezes nas páginas #2.%
	\fi}%
% ---

% ---
% Informações de dados para CAPA e FOLHA DE ROSTO
% ---
\titulo{Relatório de atividades: Uso do classificador Bayesiano} 
\autor{David Clifte\thanks{cliftedavid@gmail.com}}
\local{Brasil}
\data{2015, v-1.0}
% ---

% ---
% Configurações de aparência do PDF final

% alterando o aspecto da cor azul
\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
\makeatletter
\hypersetup{
     	%pagebackref=true,
		pdftitle={\@title}, 
		pdfauthor={\@author},
    	pdfsubject={Modelo de artigo científico com abnTeX2},
	    pdfcreator={LaTeX with abnTeX2},
		pdfkeywords={abnt}{latex}{abntex}{abntex2}{atigo científico}, 
		colorlinks=true,       		% false: boxed links; true: colored links
    	linkcolor=blue,          	% color of internal links
    	citecolor=blue,        		% color of links to bibliography
    	filecolor=magenta,      		% color of file links
		urlcolor=blue,
		bookmarksdepth=4
}
\makeatother
% --- 

% ---
% compila o indice
% ---
\makeindex
% ---

% ---
% Altera as margens padrões
% ---
\setlrmarginsandblock{4cm}{4cm}{*}
\setulmarginsandblock{4cm}{4cm}{*}
\checkandfixthelayout
% ---

% --- 
% Espaçamentos entre linhas e parágrafos 
% --- 

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

% Espaçamento simples
\SingleSpacing

% ----
% Início do documento
% ----
\begin{document}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing 

% ----------------------------------------------------------
% ELEMENTOS PRÉ-TEXTUAIS
% ----------------------------------------------------------

%---
%
% Se desejar escrever o artigo em duas colunas, descomente a linha abaixo
% e a linha com o texto ``FIM DE ARTIGO EM DUAS COLUNAS''.
% \twocolumn[    		% INICIO DE ARTIGO EM DUAS COLUNAS
%
%---
% página de titulo
\maketitle

% resumo em português
\begin{resumoumacoluna}
 Este trabalho apresenta os resultados obtidos ao aplicar o classificador
 bayessiano com opção de rejeição a 4 bases de dados públicas, são elas: Base
 de doenças coluna vertebral \cite{5349049}, base de diagnóstico de diabetes
 \cite{smith1988using}, base de diagnóstico de câncer de
 mama\cite{mangasarian1995breast} e base de haberman \cite{lo1993logistic}.
 
 Ao fim do trabalho é apresentado uma aplicação do classificador bayessiano
 combinado com um função de densidade de probabilidade do tipo janela de parzen
 à segmentação de imagens. É apresentado também a aplicação de Mistura de
 Gaussianas para segmentação de imagens.
 A implementação foi feita no Matlab\texttrademark
 
 
 \vspace{\onelineskip}
 
 \noindent
 \textbf{Palavras-chaves}: Bayes. Reconhecimento de padrões.
\end{resumoumacoluna}

% ]  				% FIM DE ARTIGO EM DUAS COLUNAS
% ---

% ----------------------------------------------------------
% ELEMENTOS TEXTUAIS
% ----------------------------------------------------------
\textual

% ----------------------------------------------------------
% Introdução
% ----------------------------------------------------------
\section*{Introdução}


% ---------------------------------------------------------- Seção de
% explicações ----------------------------------------------------------
\subsection{Estimativa de função de densidade de probabilidade}
A estimativa da distribuição de dados é importante pois permite utilizar uma
representação compacta dos dados e ainda sim mater as informações mais
relevantes da base. Existem basicamente três abordagens para estimar a função de
densidade de probabilidade de um sinal: paramétrica, não- paramétrica e
semiparamétrica. O sucesso destas representações dependem do modelo que tem sido
definido \cite{Duda}.

\subsubsection{Método não paramétrico}
Os métodos não-paramétricos não fazem nenhuma consideração da distribuição de
proba- bilidade dos dados. Em geral, estes métodos se caracterizam por conseguir
uma estimativa ade- quada para qualquer conjunto de dados que recebem como
entrada. O uso de métodos não parametricos para a estimação das funções de
densidade de probabilidade vem da falta de informações a priore sobre a a função
de densidade de probabilidade dos dados. Como exemplo de método não paramétrico
temos a janela de Parzen.




\subsubsection{Método paramétrico}
A abordagem paramétrica é geralmente usada quando a distribuição dos dados é
conhecida antecipadamente ou quando os dados são simples de forma que permitam
ser modelados usando uma distribuição conhecida, por exemplo gaussiana, Gamma,
Laplace, etc

\subsubsection{Método semi-paramétrico}
A abordagem semiparamétrica  combina a flexibilidade da abordagem
não-paramétrica e a eficiência na avaliação dos parâmetros da abordagem
paramétrica. Estes modelos utilizam um número de funções base que são sempre
menores que o conjunto de treinamento. O uso dos modelos semiparamétricos
baseados em gaussianas,GMM, tem se apresentado como uma ferramenta amplamente
usada na estimativa da PDF de qualquer sinal.

\subsection{Janela de Parzen–Rosenblatt }
A janela de Parzen, Parzen-Rosenblatt, é um método utilizado para estimar a
função de densidade de probabilidade $p(x)$ com base nas amostras presentes na
base de treinamento. A ideia basica da janela de parzen é contar quantas
amostras influenciam em determinada região R (Janela). A influencia de cada
amostra é definida a priori com a definição do Kernel. A utilização de kernels
do tipo hipercubos ou Gaussianas multivariadas são as mais comuns e ao longo
deste trabalho são utilizados apenas kernels de gaussianas multivariadas.

Definimos a influencia de uma amostra $x$ como $p(x)$. Para o caso da gaussiana
multivariada temos:
\begin{equation}
p(x)=\frac{1}{ (2 \pi)^{d/2}  |\Sigma|^{1/2}}  
exp[-\frac{1}{2}(x-\mu)^t\Sigma^{-1}(x-\mu)]
\end{equation}


Portanto a influencia total $P(x)$ é computada como:
\begin{equation}
P(x)=\frac{1}{N} \sum_{i=1}^{N}p(x_n) 
\end{equation}

Apesar da gaussiana multivariada aceitar qualquer matriz de covariancia,
contanto que esta seja regular e simetrica, neste trabalho são utilizadas
apenas matriz que possuem uma configuração $\sigma^2 I$ ou seja, uma matriz
diagonal de covariancia igual a $\sigma$.


\subsection{Gaussian Misture Models}

\subsubsection{Introdução}
Considerando um conjunto de dados $X={x_1,x_2,\ldots,x_n}| x \in R$ , a PDF dos
dados pode ser aproximada por uma família $F$ de funções de distribuição de
probabilidades em R. Em algoritmos dedicados à estimativa da PDF, o problema é
encontrar a função de distribuição $f(x) \in F$ que melhor gere os dados de
entrada.

\begin{equation}
f(x,\Theta)=\sum^{k}_{k=1}P_kg(x,\mu_k,\sigma_k)
\end{equation}

$\Theta$ é o conjunto de parâmetros do conjunto de funções que devem ser
estimados durante a fase de treinamento. Desta forma para gaussiana temos

\begin{equation}
	\Theta=
	\begin{bmatrix}
		\mu_1 & \sigma_1 \\
		\ldots & \ldots \\
		\mu_k & \sigma_k 
	\end{bmatrix}
\end{equation}

$\Theta$ pode ser estimado utilizando o Algoritmo Maximização da Expectância
(EM). O algoritmo EM é um procedimento iterativo para estimar
os parâmetros de uma mistura de gaussianas.Cada iteração do algoritmo EM
consiste em dois processos: Expectância e Maximização.
Esta aproximação se consegue através do cálculo da probabilidade de perti-
nência de um ponto às funções de distribuições na fase de expectância. Na fase
de maximização são estimados os parâmetros que maximizam cada função de
distribuição, ponderadas com os valores calculados na fase de expectância.


Na figura \ref{fig:gmmIris} é apresentado o resultado da aproximação da base da
íris. São exibidas três das quatro combinações possíveis das características da
base, essas combinações são utilizadas para realizar o treinamento do GMM.



\begin{figure}
	\centering
	\begin{tabular}{ccc}

	  %Íris
	  \includegraphics[width=40mm]{matlab/gmm/iris/1-4/Functions.eps}
	  &
	  \includegraphics[width=40mm]{matlab/gmm/iris/1-4/resultPDF.eps}
	  &
	  \includegraphics[width=40mm]{matlab/gmm/iris/1-4/resultPDF3D.eps}
	  \\
	  
	  \includegraphics[width=40mm]{matlab/gmm/iris/2-4/Functions.eps}
	  &
	  \includegraphics[width=40mm]{matlab/gmm/iris/2-4/resultPDF.eps}
	  &
	  \includegraphics[width=40mm]{matlab/gmm/iris/2-4/resultPDF3D.eps}
	  \\
	  
	  \includegraphics[width=40mm]{matlab/gmm/iris/2-3/Functions.eps}
	  &
	  \includegraphics[width=40mm]{matlab/gmm/iris/2-3/resultPDF.eps}
	  &
	  \includegraphics[width=40mm]{matlab/gmm/iris/2-3/resultPDF3D.eps}
	  \\
	  	  
	  a) Conjunto de funções
	  &
	  b) f(x)
	  &
	  c) f(x) no $R^3$
	  \\
	\end{tabular}
	\caption{Resultados obtidos ao utilizar a mistura de gaussianas para modelar
	a base de dados da íris. Na primeira linha temos o resultado do treinamento
	utilizando as informações comprimento da sepala e largura da pétala. Na linha
	seguinte temos largura da sépala e da pétala e na terceira linha o comprimento
	da sépala e largura da pétala }
	\label{fig:gmmIris}
\end{figure}


\section{Classificador de Bayes com opção de rejeição}
\subsection{Introdução}
Dada uma classificação entre M classes, o classificador de Bayes faz a seleção
da classe de um dado $x$ com base na probabilidade de $w_i$ dado um $x$ ,
$P(w_i|x)$.
Assim temos:


\begin{equation}
	x \in w_i \iff P(w_i|x) \geq P(w_j|x) \forall i \neq j
\end{equation}

\subsection{Opção de Rejeição}
Considerando o classificar de bayes um padrão é escolhido em detrimento a outro
de acordo com sua probabilidade a posteriore, A opção de rejeição sugere que de
acordo com este valor de probabilidade calculado a classificação pode ser
rejeitada pois a mesma reflete também o grau de confiança na classificação.
Desta forma podemos definir um limiar para este grau de confiança e assim caso a
probabilidade a posteriore seja menor que este limiar a amostra pode ser
classificada para a classe de rejeição. Temos a seguinte regra de
decisão para um problema com duas classes:

\begin{equation}
x \in \begin{cases}
		w_1,& \text{se }  P(w_1|x) > \beta \\
		w_2,& \text{se }  P(w_2|x) > \beta \\
		w_r,& \text{caso contrário }
	  \end{cases}
\end{equation}

\subsection{Avaliação de um classificador com Opção de Rejeição}
Algumas das métricas importantes ao utilizarmos um classificador com opção de
rejeição são taxa de erro e taxa de acurácia em função do limiar de rejeição. A
análise destas duas métricas permite identificar qual o grau de confiança ao
realizar uma classificação, bem como evitar erros ao rejeitar amostras
duvidosas. Na figura \ref{fig:TeTaVSLR}, são apresentadas as curvas obtidas
ao variar o valor desse limiar para as quatro bases em análise neste trabalho.

\begin{figure}
\begin{tabular}{c c c}

  
  \multicolumn{3}{c}{Coluna Vertebral}\\ \hline
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gauss}{vertebra}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gmm}{vertebra}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{parzenGauss}{vertebra}} \\
  (a) Gaussian & (b) GMM & (c) Janela de Parzen \\
  \\
  \multicolumn{3}{c}{Câncer de mama}\\ \hline
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gauss}{breastC}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gmm}{breastC}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{parzenGauss}{breastC}} \\
  (d) Gaussian & (e) GMM & (f) Janela de Parzen \\
  \\
  \multicolumn{3}{c}{Diabetes}\\ \hline
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gauss}{diab}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gmm}{diab}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{parzenGauss}{diab}} \\
  (g) Gaussian & (h) GMM & (i) Janela de Parzen \\
  \\  
  \multicolumn{3}{c}{Haberman}\\ \hline
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gauss}{haber}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{gmm}{haber}} &
  \includegraphics[width=\textwidth / 3]{\pathForTaxaErroRejeicaBase{parzenGauss}{haber}} \\
  (j) Gaussian & (k) GMM & (l) Janela de Parzen \\
  \\

\end{tabular}
\caption{Taxa de Erro e Taxa de Rejeição em função do limiar de rejeição
utilizando a função gaussiana como PDF.
Em verde a taxa de rejeição em vermelho a taxa de erro.}
\label{fig:TeTaVSLR}
\end{figure}

Na figura \ref{fig:TeTaVSLR}, os limiares de rejeição $\beta$ variam de 0 a 1.
Podemos perceber que a taxa de rejeição aumenta somente a partir de 0,5. Isso ocorre
devido a tomada de decisão ser feita apenas para duas classes, dessa forma, para
um limiar inferior a 50\% sempre haverá uma classe com uma probabilidade a
porteriore maior.

O desempenho de um classificador com capacidade de rejeição pode ser descrito através de
uma curva que leva em consideração a taxa de classificação (acurácia) em relação à sua taxa de
rejeição. Esta representação é denominada curva A-R (Accuracy-Reject Curve), em que cada
valor correspondente a uma taxa de erro e a uma taxa de rejeição que depende do custo de
rejeição $W_r$ \cite{AJALMAR}. Esses valores são obtidos à partir da minimização
do erro empírico que é calculado atravéz da soma ponderada do erro e da taxa de
rejeição obtidos para um valor de limiar de rejeição. Temos o erro
empírico definido a seguir.
\begin{equation}
	E_{empírico}(\beta) = E(\beta) + W_r R(\beta) 
\end{equation}

Dessa forma podemos obter o erro empírico para cada uma das bases, figura
\ref{fig:empError} em função do valor de $\beta$ e de $W_r$. Na figura são
exibidos apenas os $W_r$ que geram um par $(E(\beta),R(\beta))$ distintos. Esse
par ordenado é utilizado para gerar os gráfico da curava A-R exibido na figura
\ref{fig:ar}.


\begin{figure}
\begin{tabular}{c c c}

\multicolumn{3}{c}{Erro Empírico}\\ \hline \hline
\multicolumn{3}{c}{Coluna vertebral}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gauss}{vertebra}} & 
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gmm}{vertebra}} &
\includegraphics[width=\textwidth / 3]{\pathForEmpError{parzenGauss}{vertebra}}\\
(a) Gaussiana & (b) GMM & (c) Janela de Parzen \\
\\
\multicolumn{3}{c}{Câncer de Mama}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gauss}{breastC}} & 
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gmm}{breastC}} &
\includegraphics[width=\textwidth / 3]{\pathForEmpError{parzenGauss}{breastC}} \\
(d) Gaussiana & (e) GMM & (f) Janela de Parzen \\
\\
\multicolumn{3}{c}{Diabetes}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gauss}{diab}} & 
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gmm}{diab}} &
\includegraphics[width=\textwidth / 3]{\pathForEmpError{parzenGauss}{diab}} \\
(g) Gaussiana & (h) GMM & (i) Janela de Parzen \\
\\
\multicolumn{3}{c}{Haberman}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gauss}{haber}} & 
\includegraphics[width=\textwidth / 3]{\pathForEmpError{gmm}{haber}} &
\includegraphics[width=\textwidth / 3]{\pathForEmpError{parzenGauss}{haber}} \\
(j) Gaussiana & (k) GMM & (l) Janela de Parzen \\

 
\end{tabular}
\caption{Cada curva em cada um dos gráficos reflete o erro empírico em função
de algum $W_r$. O valor de cada $W_r$ utilizado para gerar as curvas podem ser
visualizado com mais detalhes na tabela \ref{tab:wrBase}.}
\label{fig:empError}
\end{figure} 


\begin{figure}
\begin{tabular}{c c c}

\multicolumn{3}{c}{Curva A-R}\\ \hline \hline
\multicolumn{3}{c}{Coluna vertebral}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForAR{gauss}{vertebra}} & 
\includegraphics[width=\textwidth / 3]{\pathForAR{gmm}{vertebra}} &
\includegraphics[width=\textwidth / 3]{\pathForAR{parzenGauss}{vertebra}}\\
(a) Gaussiana & (b) GMM & (c) Janela de Parzen \\
\\
\multicolumn{3}{c}{Câncer de Mama}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForAR{gauss}{breastC}} & 
\includegraphics[width=\textwidth / 3]{\pathForAR{gmm}{breastC}} &
\includegraphics[width=\textwidth / 3]{\pathForAR{parzenGauss}{breastC}} \\
(d) Gaussiana & (e) GMM & (f) Janela de Parzen \\
\\
\multicolumn{3}{c}{Diabetes}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForAR{gauss}{diab}} & 
\includegraphics[width=\textwidth / 3]{\pathForAR{gmm}{diab}} &
\includegraphics[width=\textwidth / 3]{\pathForAR{parzenGauss}{diab}} \\
(g) Gaussiana & (h) GMM & (i) Janela de Parzen \\
\\
\multicolumn{3}{c}{Haberman}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForAR{gauss}{haber}} & 
\includegraphics[width=\textwidth / 3]{\pathForAR{gmm}{haber}} &
\includegraphics[width=\textwidth / 3]{\pathForAR{parzenGauss}{haber}} \\
(j) Gaussiana & (k) GMM & (l) Janela de Parzen \\

 
\end{tabular}
\caption{Cada curva em cada um dos gráficos reflete o erro empírico em função
de algum $W_r$. O valor de cada $W_r$ utilizado para gerar as curvas podem ser
visualizado com mais detalhes na tabela \ref{tab:wrBase}.}
\label{fig:ar}
\end{figure} 

Os mínimos de cada $W_r$ são exibidos na tabela \ref{tab:wrBase}


\begin{table}
    \tiny
	\begin{tabular}{c c c}
	
	\multicolumn{3}{c}{Erro Empírico}\\ \hline \hline
	 
	
	
	\multicolumn{3}{c}{Coluna vertebral}\\ \hline
	\importWRTable{gauss}{vertebra} & 
 	\importWRTable{gmm}{vertebra} &
 	\importWRTable{parzenGauss}{vertebra} \\
 	
 	(a) Gaussiana & (b) GMM & (c) Janela de Parzen \\ %\\

	\\
	\multicolumn{3}{c}{Câncer de Mama}\\ \hline
	\importWRTable{gauss}{breastC} &
	\importWRTable{gmm}{breastC} &
	\importWRTable{parzenGauss}{breastC} \\
	(d) Gaussiana & (e) GMM & (f) Janela de Parzen \\

	\\
	\multicolumn{3}{c}{Diabetes}\\ \hline
	\importWRTable{gauss}{diab} &
	\importWRTable{gmm}{diab} &
	\importWRTable{parzenGauss}{diab} \\
	(g) Gaussiana & (h) GMM & (i) Janela de Parzen \\

	\\
	\multicolumn{3}{c}{Haberman}\\ \hline
	\importWRTable{gauss}{haber} &
	\importWRTable{gmm}{haber} &
	\importWRTable{parzenGauss}{haber} \\
	(j) Gaussiana & (k) GMM & (l) Janela de Parzen \\


	\end{tabular}
	\caption{Cada tabela exibe a acurácia e a taxa de rejeição ótimos encontrado
	para algum limiar $\beta_o$ em função de $W_r$ para cada uma das bases
	utilizando três diferentes PDFs.}
\label{tab:wrBase}
\end{table} 








\subsubsection{Impacto na região de decisão}
Ao optarmos por um classificador com opção de rejeição criamos uma nova classe
que acolherá os dados que não puderam ser discriminados para alguma das outras
duas classes, dessa forma, a classe de rejeição também define uma região de
decisão. Essa região tem sua área controlada pelo valor do limiar de rejeição e
sempre inicializa na região de interseção das outras duas classes. Nas figuras
\ref{fig:regDecRejLmGauss},\ref{fig:regDecRejLmGMM} e
\ref{fig:regDecRejLmParzen} são exibidas as regiões de decisões controladas com
o limiar de rejeição utilizando 3 diferentes funções de densidade de
probabilidade.

 




\begin{figure}
\begin{tabular}{c c c}

\multicolumn{3}{c}{PDF Gaussiana com RejOption}\\ \hline \hline
\multicolumn{3}{c}{Coluna vertebral}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{vertebra}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{vertebra}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{vertebra}{0.944}}\\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Câncer de Mama}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{breastC}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{breastC}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{breastC}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Diabetes}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{diab}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{diab}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{diab}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Haberman}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{haber}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{haber}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{haber}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\


\end{tabular}
\caption{Região de decisão formada utilizando três diferentes funções de
densidade de probabilidade. Foram testados três valores de limiar de rejeição
$\beta$ para as três bases.}
\label{fig:regDecRejLmGauss}
\end{figure} 




\begin{figure}
\begin{tabular}{c c c}

\multicolumn{3}{c}{PDF GMM com RejOption}\\ \hline \hline
\multicolumn{3}{c}{Coluna vertebral}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{vertebra}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{vertebra}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{vertebra}{0.944}}\\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Câncer de Mama}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{breastC}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{breastC}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{breastC}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Diabetes}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{diab}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{diab}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{diab}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Haberman}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{haber}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{haber}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{gmm}{haber}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\


\end{tabular}
\caption{Região de decisão formada utilizando mistura de gaussianas como função
de densidade de probabilidade. Para todos os exemplos foram utilizadas 3
gaussianas para modelar cada classe. Foram testados 3 valores de limiar de
rejeição $\beta$ para as três bases.}
\label{fig:regDecRejLmGMM}
\end{figure} 

 



\begin{figure}
\begin{tabular}{c c c}

\multicolumn{3}{c}{PDF Janela de Parzen com RejOption}\\ \hline \hline
\multicolumn{3}{c}{Coluna vertebral}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{vertebra}{0.556}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{vertebra}{0.833}} & \includegraphics[width=\textwidth / 3]{\pathForRejDec{gauss}{vertebra}{0.944}}\\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Câncer de Mama}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{breastC}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{breastC}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{breastC}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Diabetes}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{diab}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{diab}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{diab}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\
\\
\multicolumn{3}{c}{Haberman}\\ \hline
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{haber}{0.556}} & 
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{haber}{0.833}} &
\includegraphics[width=\textwidth / 3]{\pathForRejDec{parzenGauss}{haber}{0.944}} \\
(a) $\beta=0.556$ & (b) $\beta=0.833$ & (c) $\beta=0.944$ \\


\end{tabular}
\caption{Região de decisão formada utilizando janela de Parzen como função de
densidade de probabilidade. Foram testados três valores de limiar de rejeição
$\beta$ para as três bases.}
\label{fig:regDecRejLmParzen}
\end{figure} 

\section{Segmentação de imagem utilizando o classificador de bayes} 
Nas figuras \ref{fig:resultGaussSegEUA} e \ref{fig:resultGaussSegEUA}
são apresentados os resultados da segmentação de duas imagens utilizando o
classificador Bayessiano com janela de parzen como função de densidade de
probabilidade. Para ambas as imagens foram testados os valores,
$0.0100*10^{-4}$, $0.1733*10^{-4}$, $0.3367*10^{-4}$ e $0.5000*10^{-4}$ para a
variancia da janela de Parzen.


A segmentação de uma imagem é realizada levando em
consideração a intensidade normalizada entre 0 e 1 dos pixels nas três
componentes RGB.
A definição dos dados de de uma classe é feita a partir da seleção de $k$
regiões da imagem, não necessariamente de mesma área $A_i$. A área é utilizada
para calcular a probabilidade a priore por isso classes com uma diferença de
área muito grande podem impactar na classificação.
Assim temos:

\begin{equation}
	P(w_i) =  \frac{A_i}{\sum_{i=1}^{k}{A_J}}
\end{equation}erro

Para o cálculo da acurácia da segmentação, foi definida uma máscara para cada
uma das imagens. Foi realizada a comparação pixel a pixel e o resultado obtido
para cada imagem é exibido na tabela \ref{tab:accParzenSeg}.

\begin{figure}
	\centering
	\begin{tabular}{cc}
	  \multicolumn{2}{c}{ \includegraphics[width=45mm]{matlab/parzenGauss/Seg/euaDif.png}}\\
	  \multicolumn{2}{c}{(a) Original}\\
	   
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_1e-06_Result}.png}&
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_1.73e-05_Result}.png}
	  \\
	  (b) h=$0.0100*10^{-4}$ &  (c) h=$0.1733*10^{-4}$\\
	  
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_3.37e-05_Result}.png}&
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_5e-05_Result}.png}
	   \\
	  (d) h=$0.3367*10^{-4}$ & (e) h=$0.5000*10^{-4}$\\
	  
	  
	  \multicolumn{2}{c}{
		\begin{tabular}{c c c}
			  \includegraphics[width=30mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_classe_1}.png}.
			  &
			  \includegraphics[width=30mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_classe_2}.png}
			  &
			  \includegraphics[width=30mm]{{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_classe_3}.png}
	  		\\
	  		(e) Classe 1 & (f) Classe 2 & (g) Classe 3 
	  	\end{tabular}
	  }

	\end{tabular}
	\caption{Resultado da segmentação utilizando o classificador Bayessiano com
	janela de parzen.
	Com o aumento do valor de h pode-se notar que a segmentação se torna mais
	suave.}
	\label{fig:resultGaussSegEUA}
\end{figure}




\begin{figure} 
	\centering
	\begin{tabular}{cc}
	
	  \multicolumn{2}{c}{ \includegraphics[width=45mm]{matlab/parzenGauss/Seg/japanFlag.png}}\\
	  \multicolumn{2}{c}{(a) Original}\\	
	
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_1e-06_Result}.png} &
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_1.73e-05_Result}.png}
	  \\
	  (b) h=$0.0100*10^{-4}$ &  (c) h=$0.1733*10^{-4}$\\
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_3.37e-05_Result}.png}&
	  \includegraphics[width=45mm]{{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_5e-05_Result}.png}
	   \\
	  (d) h=$0.3367*10^{-4}$ & (e) h=$0.5000*10^{-4}$\\
	  
	  
	  \multicolumn{2}{c}{
		\begin{tabular}{c c }
			  \includegraphics[width=30mm]{{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_classe_1}.png}.
			  &
			  \includegraphics[width=30mm]{{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_classe_2}.png}
	  		\\
	  		(e) Classe 1 & (f) Classe 2 
	  	\end{tabular}
	  }

	\end{tabular}
	\caption{Resultado da segmentação utilizando o classificador Bayessiano com
	janela de parzen.
	Com o aumento do valor de h pode-se notar que a segmentação se torna mais
	suave.}
	\label{fig:resultGaussSegJapan}
\end{figure}

\begin{table} 
	\centering
	\begin{tabular}{c c}
		Bandeira dos EUA & Bandeira do Japão\\
		
		
		\begin{tabular}[t]{c|c}%
		    \bfseries $h$ & 
		    \bfseries $Acurácia$
		    \csvreader[no head]
		    	{matlab/parzenGauss/Seg/euaDif.png_parzenGauss_AccVsH_Result.csv}{}% use
		    % head of csv as column names
		    {\\\hline\csvcolii&\csvcoli}% specify your coloumns
		   	% here
	   		\\\hline
	    \end{tabular}
	    
	    &
	    
	    \begin{tabular}[t]{c|c}%
		    \bfseries $h$ & 
		    \bfseries $Acurácia$
		    \csvreader[no
		    head]{matlab/parzenGauss/Seg/japanFlag.png_parzenGauss_AccVsH_Result.csv}{}% use head of csv as column names
		    {\\\hline\csvcolii&\csvcoli}% specify your coloumns
		    % here
	    	\\\hline
	    \end{tabular}
	    \\
	\end{tabular}
	\caption{Acurácia obtida em função do tamanho da janela para as imagens da
	bandeira do Japão e dos Estados Unidos}
	\label{tab:accParzenSeg}
\end{table}


\section{Segmentação de imagem utilizando GMM}
 A utilização da mistura de gaussianas como ferramenta de segmentação autmática
 se dá na escolha de K regiões semelhantes, onde o valor de K é inicialmente
 acertado. O atributo levado em consideração para o calculo da semelhança é a
 intensidade dos 3
canais, R, G e B da imagem \cite{IMAGE_SEG_GMM}.
Os resultados obtidos com a segmentação utilizando GMM são exibidos na figura
\ref{fig:resultGMMSeg}.

\begin{figure}
	\centering
	\begin{tabular}{cc}
	  \includegraphics[width=45mm]{{matlab/gmm/Seg/japanFlag.png_gmm_2_Result}.png}&
	  \includegraphics[width=45mm]{{matlab/gmm/Seg/japanFlag.png_gmm_3_Result}.png}
	  \\
	  (b) K=2 &  (c) K=3\\
	  
	  \includegraphics[width=45mm]{{matlab/gmm/Seg/euaDif.png_gmm_3_Result}.png}&
	  \includegraphics[width=45mm]{{matlab/gmm/Seg/euaDif.png_gmm_4_Result}.png}
	   \\
	  (b) K=3 &  (c) K=4\\


	\end{tabular}
	\caption{Resultado da segmentação utilizando GMM. Na bandeira do Japão com o
	aumento do valor de K foi possível separar as sombras da bandeira. O mesmo
	ocorreu com a bandeira do EUA. Para o valor K correto, 2 para a bandeira do
	Japão e 3 para dos EUA, foi possível segmentar bem as imagens para a bandeira
	dos EUA. Para a bandeira do Japão houve uma confusão entre o centro vermelho e
	algumas regiões de sombra}
	\label{fig:resultGMMSeg}
\end{figure}












\bookmarksetup{startatroot}% 
% ---

% ---
% Conclusão
% % ---
% 
% \section*{Considerações finais}
% 
% 
% 
% 
% \addcontentsline{toc}{section}{Considerações finais}
% Neste trabalho foram apresentados os resultados obtidos ao testar várias funções
% de densidade de probabilidade junto ao classificador bayessiano. Os resultados
% podem ser visualizados na tabela \ref{tab:acuracia}. Podemos observar uma
% superioridade dos métodos não lineares frente aos lineares, bem como uma maior
% acurácia para métodos que consideram melhor a modelagem dos dados, quando se
% utiliza matrizes de covariância diferentes para cada classe de problema.
% 

% ----------------------------------------------------------
% ELEMENTOS PÓS-TEXTUAIS
% ----------------------------------------------------------
\postextual

% ----------------------------------------------------------
% Referências bibliográficas
% ----------------------------------------------------------
\bibliography{bib}

% ----------------------------------------------------------
% Glossário
% ------------------------------------ ----------------------
%
% Há diversas soluções prontas para glossário em LaTeX. 
% Consulte o manual do abnTeX2 para obter sugestões.
% 
%\glossary 

% ----------------------------------------------------------
% Apêndices
% ----------------------------------------------------------


\end{document}